{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRYSosEZ5MopW/0Hihjh0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllAboutAI-YT/FT/blob/main/PDF_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q-UH04bhtL-s"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "\n",
        "!pip install -q pdfplumber\n",
        "\n",
        "!pip install -q glob2\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import pdfplumber\n",
        "from time import time,sleep\n",
        "import textwrap\n",
        "import re\n",
        "import glob2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "def convert_pdf2txt(src_dir, dest_dir):\n",
        "    files = os.listdir(src_dir)\n",
        "    files = [i for i in files if '.pdf' in i]\n",
        "    for file in files:\n",
        "        try:\n",
        "            with pdfplumber.open(src_dir+file) as pdf:\n",
        "                output = ''\n",
        "                for page in pdf.pages:\n",
        "                    output += page.extract_text()\n",
        "                    output += '\\n\\nNEW PAGE\\n\\n'  # change this for your page demarcation\n",
        "                save_file(dest_dir+file.replace('.pdf','.txt'), output.strip())\n",
        "        except Exception as oops:\n",
        "            print(oops, file)\n",
        "            \n",
        "openai.api_key = open_file('openaiapikey.txt')\n",
        "\n",
        "#THIS FUNCTION USES CURIE-001 TO SUMMARIZE (CHEAPER)\n",
        "def gpt_3 (prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-curie-001\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=700,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "    text = response['choices'][0]['text'].strip()\n",
        "    return text\n",
        "\n",
        "#THIS FUNCTION USES DAVINCI-003\n",
        "def gpt_31 (prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=700,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "    text = response['choices'][0]['text'].strip()\n",
        "    return text\n",
        "if __name__ == '__main__':\n",
        "    #Call PDF Converter Function\n",
        "    convert_pdf2txt('PDFs/', 'textPDF/')\n",
        "    \n",
        "    #Your Pathfolder\n",
        "    pathfolder = '/content/textPDF'\n",
        "    \n",
        "    # get a list of all text files in the specified folder\n",
        "    files = glob2.glob(f'{pathfolder}/*.txt')\n",
        "    \n",
        "    # initialize an empty string to store the contents of all the text files\n",
        "    alltext = \"\"\n",
        "    \n",
        "\n",
        "    # iterate over the list of files\n",
        "    for file in files:\n",
        "        with open(file, 'r') as infile:  # open the file\n",
        "            alltext += infile.read()  # read the contents of the file and append it to the alltext string\n",
        "    chunks = textwrap.wrap(alltext, 4000)\n",
        "    result = list()\n",
        "    count = 0\n",
        "    \n",
        "    #write a summary\n",
        "    for chunk in chunks:\n",
        "        count = count + 1\n",
        "        prompt = open_file('prompt.txt').replace('<<SUMMARY>>', chunk)\n",
        "        prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "        summary = gpt_3(prompt)\n",
        "        print('\\n\\n\\n', count, 'out of', len(chunks), 'Compressions', ' : ', summary)\n",
        "        result.append(summary)\n",
        "        save_file(\"pdfsummary.txt\", '\\n\\n'.join(result))\n",
        "\n",
        "# Split the contents of pfdsummary.txt into chunks with a textwrap of 3000\n",
        "    with open(\"pdfsummary.txt\", 'r', encoding='utf-8') as infile:\n",
        "        summary = infile.read()\n",
        "        chunks = textwrap.wrap(summary, 3000)\n",
        "\n",
        "    #Initialize empty lists to store the results\n",
        "    result = []\n",
        "    result2 = []\n",
        "\n",
        "    #WRITE NOTES FROM CHUNKS\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        # Read the contents of prompt2.txt\n",
        "        with open(\"prompt2.txt\", 'r', encoding='utf-8') as infile:\n",
        "            prompt = infile.read()\n",
        "\n",
        "        # Replace the placeholder in the prompt with the current chunk\n",
        "        prompt = prompt.replace(\"<<NOTES>>\", chunk)\n",
        "\n",
        "        # Run the chunk through the gpt_3 function\n",
        "        notes = gpt_3(prompt)\n",
        "        \n",
        "        #WRITE A SUMMARY FROM NOTES\n",
        "        keytw = open_file('prompt6.txt').replace('<<NOTES>>', chunk)\n",
        "        keytw2 = gpt_31(keytw)\n",
        "\n",
        "\n",
        "        # Print the result\n",
        "        print(f\"\\n\\n\\n{i+1} out of {len(chunks)} Compressions: {notes}\")\n",
        "\n",
        "        # Append the results to the lists\n",
        "        result.append(notes)\n",
        "        result2.append(keytw2)\n",
        "\n",
        "\n",
        "    #Save the results to a file\n",
        "    with open(\"notes.txt\", 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(\"\\n\\n\".join(result))\n",
        "        \n",
        "    with open(\"notessum.txt\", 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(\"\\n\\n\".join(result2))\n",
        "    #SUMMARY OF NOTES\n",
        "    sumnotes = open_file(\"notessum.txt\")\n",
        "    \n",
        "    \n",
        "    #WRITE A STEP BY STEP GUIDE FROM NOTES\n",
        "    #keytw = open_file('prompt3.txt').replace('<<NOTES>>', sumnotes)\n",
        "    #keytw2 = gpt_31(keytw)\n",
        "    #print(keytw2)\n",
        "    #save_file(\"steps.txt\", keytw2)  \n",
        "\n",
        "        \n",
        "    #WRITE ESSENCIAL INFO\n",
        "    essencial1 = open_file('prompt4.txt').replace('<<NOTES>>', sumnotes)\n",
        "    essencial2 = gpt_31(essencial1)\n",
        "    print(essencial2)\n",
        "    save_file(\"essencial.txt\", essencial2)    \n",
        "    \n",
        "    #WRITE A BLOG POST\n",
        "    blogpost = open_file('essencial.txt')\n",
        "    blogpostw = open_file('prompt5.txt').replace('<<NOTES>>', blogpost)\n",
        "    blogpostw2 = gpt_31(blogpostw)\n",
        "    print(blogpostw2)\n",
        "    save_file(\"blogpost.txt\", blogpostw2)\n",
        "    \n",
        "  \n",
        "    #WRITE A VISUAL PROMPT\n",
        "    #midj = open_file(\"essencial.txt\")\n",
        "    #mjv4 = open_file('mjv4prompts.txt').replace('<<SCENE>>', midj)\n",
        "    #desc = gpt_31(mjv4)\n",
        "    #print('\\n\\n', desc)\n",
        "    #save_file(\"midprompts.txt\", desc)"
      ],
      "metadata": {
        "id": "2GT9SP3kubQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}